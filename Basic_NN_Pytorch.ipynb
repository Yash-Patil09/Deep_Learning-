{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Patil09/Deep_Learning-/blob/main/Basic_NN_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "mlKhI6gL_rGv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n1. LINEAR LAYER (nn.Linear)\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j4ETJes_11n",
        "outputId": "4f01e5d8-ffe0-48c2-fa97-7f5caef21b15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. LINEAR LAYER (nn.Linear)\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Implement of Perceptron**"
      ],
      "metadata": {
        "id": "llAHpSVEBqaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear layer performs: output = input @ weight.T + bias\n",
        "linear = nn.Linear(in_features=3, out_features=2)"
      ],
      "metadata": {
        "id": "CA-MWqVm_7zR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Linear layer: input_size=3, output_size=2\")\n",
        "print(f\"Weight matrix shape: {linear.weight.shape}\")  # (2, 3)\n",
        "print(f\"Bias vector shape: {linear.bias.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79oaOLHUAShX",
        "outputId": "6f2f3557-164a-4b46-f3ac-e0a26e4436d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear layer: input_size=3, output_size=2\n",
            "Weight matrix shape: torch.Size([2, 3])\n",
            "Bias vector shape: torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = torch.tensor([1.0,2.0,3.0])\n",
        "output = linear(input_data)\n",
        "print(f'Input data:{input_data}')\n",
        "print(f'Output data:{output}')\n",
        "print(f\"Formula: output = input @ weight.T + bias\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iympDlCEAc0V",
        "outputId": "00ffe944-bb61-4f81-879e-10999b4861ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:tensor([1., 2., 3.])\n",
            "Output data:tensor([-2.7454,  0.2469], grad_fn=<ViewBackward0>)\n",
            "Formula: output = input @ weight.T + bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Manual Calculations\n",
        "manual_op = input_data @ linear.weight.T + linear.bias\n",
        "print(f\"Manual calculation: {manual_op}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6THN2il5A_dV",
        "outputId": "6339d795-f659-492d-c6bf-4d1a411131a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual calculation: tensor([-2.7454,  0.2469], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Functions**"
      ],
      "metadata": {
        "id": "I45TX9lhB79O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n2. ACTIVATION FUNCTIONS\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvHDrMtGBWUv",
        "outputId": "578d8d91-0f86-4208-d381-7a8289f08f3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "2. ACTIVATION FUNCTIONS\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
        "print(f\"Input: {x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7Dlwh98CIgR",
        "outputId": "a6d2d354-3651-4f90-f255-9ceb10ee76e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([-2., -1.,  0.,  1.,  2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ReLU: Returns max(0, x)\n",
        "2. Sigmoid: Maps to (0, 1)\n",
        "3. Tanh: Maps to (-1, 1)\n"
      ],
      "metadata": {
        "id": "auHu4zOlCWzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relu = nn.ReLU()\n",
        "relu_out = relu(x)\n",
        "print(f\"ReLU: {relu_out}\")\n",
        "print(\"ReLU kills negative values, keeps positive ones\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2huRVQ4cCRRV",
        "outputId": "c38031a4-aafa-4571-b480-7b1722259cb0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU: tensor([0., 0., 0., 1., 2.])\n",
            "ReLU kills negative values, keeps positive ones\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid = nn.Sigmoid()\n",
        "sigmoid_out = sigmoid(x)\n",
        "print(f'Sigmoid: {sigmoid_out}')\n",
        "print(\"Sigmoid maps values to (0, 1)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7_hc-I4CzrS",
        "outputId": "22ca1cf7-28bf-491a-baee-9695f634f4dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid: tensor([0.1192, 0.2689, 0.5000, 0.7311, 0.8808])\n",
            "Sigmoid maps values to (0, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tanh = nn.Tanh()\n",
        "tanh_out = tanh(x)\n",
        "print(f'Tanh: {tanh_out}')\n",
        "print(\"Tanh maps values to (-1, 1)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARQd4_deC_Pa",
        "outputId": "87e1feba-dd7a-4c75-f89b-74736fcbc7d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tanh: tensor([-0.9640, -0.7616,  0.0000,  0.7616,  0.9640])\n",
            "Tanh maps values to (-1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOSS FUNCTIONS**"
      ],
      "metadata": {
        "id": "9Whx6nxHEvLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE Loss for regression\n",
        "mse_loss = nn.MSELoss()\n",
        "predictions = torch.tensor([2.5, 1.8, 3.1])\n",
        "targets = torch.tensor([2.0, 2.0, 3.0])\n",
        "mse = mse_loss(predictions, targets)\n",
        "print(f\"MSE Loss Example:\")\n",
        "print(f\"Predictions: {predictions}\")\n",
        "print(f\"Targets: {targets}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(\"MSE = mean((pred - target)^2)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_4HdeKvDM1_",
        "outputId": "e7523152-1f3e-49c7-d849-8f898401d078"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Loss Example:\n",
            "Predictions: tensor([2.5000, 1.8000, 3.1000])\n",
            "Targets: tensor([2., 2., 3.])\n",
            "MSE: 0.1000\n",
            "MSE = mean((pred - target)^2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy for classification\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "# 3 classes, 2 samples\n",
        "logits = torch.tensor([[2.0, 1.0, 0.1],   # Sample 1: class 0 most likely\n",
        "                       [0.5, 2.5, 0.3]])  # Sample 2: class 1 most likely\n",
        "labels = torch.tensor([0, 1])  # True classes\n",
        "ce = ce_loss(logits, labels)\n",
        "print(f\"\\nCrossEntropy Loss Example:\")\n",
        "print(f\"Logits: {logits}\")\n",
        "print(f\"True labels: {labels}\")\n",
        "print(f\"CE Loss: {ce:.4f}\")\n",
        "print(\"Lower loss = better predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrt3tU8aER6f",
        "outputId": "37347c93-7ce2-474c-8f1b-bb578154ce81"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CrossEntropy Loss Example:\n",
            "Logits: tensor([[2.0000, 1.0000, 0.1000],\n",
            "        [0.5000, 2.5000, 0.3000]])\n",
            "True labels: tensor([0, 1])\n",
            "CE Loss: 0.3185\n",
            "Lower loss = better predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Layer Perceptron or MLP**"
      ],
      "metadata": {
        "id": "zulwhAX3Fsvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n5. BUILDING A NEURAL NETWORK\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "class ExplainedNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Layer 1: 4 inputs -> 8 hidden units\n",
        "        self.layer1 = nn.Linear(4, 8)\n",
        "        # Layer 2: 8 hidden -> 3 outputs\n",
        "        self.layer2 = nn.Linear(8, 3)\n",
        "        # Activation function\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"  Input shape: {x.shape}\")\n",
        "\n",
        "        # First layer + activation\n",
        "        x = self.layer1(x)\n",
        "        print(f\"  After layer1: {x.shape}\")\n",
        "        x = self.relu(x)\n",
        "        print(f\"  After ReLU: {x.shape}\")\n",
        "\n",
        "        # Second layer (output)\n",
        "        x = self.layer2(x)\n",
        "        print(f\"  Final output: {x.shape}\")\n",
        "        return x\n",
        "\n",
        "# Create and test network\n",
        "net = ExplainedNN()\n",
        "print(f\"Network architecture:\")\n",
        "print(net)\n",
        "\n",
        "# Test forward pass\n",
        "batch_input = torch.randn(2, 4)  # 2 samples, 4 features each\n",
        "print(f\"\\nForward pass:\")\n",
        "output = net(batch_input)\n",
        "print(f\"Final result shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMiFU-9fEpTC",
        "outputId": "f35329d8-abfe-45e8-d68d-7aeee784479a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "5. BUILDING A NEURAL NETWORK\n",
            "----------------------------------------\n",
            "Network architecture:\n",
            "ExplainedNN(\n",
            "  (layer1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (layer2): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "\n",
            "Forward pass:\n",
            "  Input shape: torch.Size([2, 4])\n",
            "  After layer1: torch.Size([2, 8])\n",
            "  After ReLU: torch.Size([2, 8])\n",
            "  Final output: torch.Size([2, 3])\n",
            "Final result shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIMIZERS**"
      ],
      "metadata": {
        "id": "wef08SdWLs5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create simple model for demo\n",
        "model = nn.Linear(2, 1)\n",
        "print(model)\n",
        "print(f\"Model parameters before training:\")\n",
        "print(f\"Weight: {model.weight.data}\")\n",
        "print(f\"Bias: {model.bias.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsVgMEhOHIk4",
        "outputId": "a0f4f623-7978-45fe-8455-1f07a95b65cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=2, out_features=1, bias=True)\n",
            "Model parameters before training:\n",
            "Weight: tensor([[0.1883, 0.3693]])\n",
            "Bias: tensor([-0.1151])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "adam = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "print(f\"\\nOptimizers:\")\n",
        "print(f\"SGD: Simple gradient descent: {sgd}\")\n",
        "print(f\"Adam: Adaptive learning rate (usually better): {adam}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OYt6Q-mLxts",
        "outputId": "50783ce5-f98d-435c-8a36-2c1c1e04c084"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizers:\n",
            "SGD: Simple gradient descent: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adam: Adaptive learning rate (usually better): Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "3JHKYub1RWpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(10,2)\n",
        "y = (2*X[:,0]+1*X[:,1]+1).unsqueeze(1)"
      ],
      "metadata": {
        "id": "5uapU7eTNaeg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(2,1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "2jSZbpZXRxm3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training to learn: y = 2*x1 + 1*x2 + 1\")\n",
        "print(f\"Initial loss: {criterion(model(X), y).item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhruD4QBSPSW",
        "outputId": "c2d968f9-6bce-4ffc-9916-1a8652068818"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training to learn: y = 2*x1 + 1*x2 + 1\n",
            "Initial loss: 2.1181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(3):\n",
        "  print(f\"\\nStep {step + 1}:\")\n",
        "\n",
        "  predictions = model(X)\n",
        "  loss = criterion(predictions,y)\n",
        "  print(f\"  1. Forward pass - Loss: {loss.item():.4f}\")\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  print(f\"2. Zero Grad\")\n",
        "\n",
        "  loss.backward()\n",
        "  print(f\"  3. Backward pass - Compute gradients\")\n",
        "\n",
        "  # 4. Update parameters\n",
        "  optimizer.step()\n",
        "  print(f\"  4. Update parameters\")\n",
        "  print(f\"     New weight: {model.weight.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMuBcXR1SYGn",
        "outputId": "22355f47-a021-4dd2-d0e1-d39702fb34a9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 1:\n",
            "  1. Forward pass - Loss: 2.1181\n",
            "2. Zero Grad\n",
            "  3. Backward pass - Compute gradients\n",
            "  4. Update parameters\n",
            "     New weight: tensor([[ 0.5761, -0.3532]])\n",
            "\n",
            "Step 2:\n",
            "  1. Forward pass - Loss: 2.0833\n",
            "2. Zero Grad\n",
            "  3. Backward pass - Compute gradients\n",
            "  4. Update parameters\n",
            "     New weight: tensor([[ 0.5861, -0.3432]])\n",
            "\n",
            "Step 3:\n",
            "  1. Forward pass - Loss: 2.0488\n",
            "2. Zero Grad\n",
            "  3. Backward pass - Compute gradients\n",
            "  4. Update parameters\n",
            "     New weight: tensor([[ 0.5961, -0.3332]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DROPOUT AND BATCH NORMALIZATION**"
      ],
      "metadata": {
        "id": "jvbq3CUTZ0Xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hq51t5O_Z0Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout: Randomly sets some neurons to zero\n",
        "dropout = nn.Dropout(p=0.5)  # 50% chance to zero out\n",
        "x = torch.ones(1, 5)\n",
        "print(f\"Before dropout: {x}\")\n",
        "print(f\"After dropout: {dropout(x)}\")\n",
        "print(\"Dropout prevents overfitting by randomly turning off neurons\")\n",
        "\n",
        "# Batch Normalization: Normalizes inputs to have mean=0, std=1\n",
        "batch_norm = nn.BatchNorm1d(3)\n",
        "x = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                  [4.0, 5.0, 6.0],\n",
        "                  [7.0, 8.0, 9.0]])\n",
        "print(f\"\\nBefore BatchNorm - mean: {x.mean(dim=0)}\")\n",
        "normalized = batch_norm(x)\n",
        "print(f\"After BatchNorm - mean: {normalized.mean(dim=0)}\")\n",
        "print(\"BatchNorm helps with training stability\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zApw82TVor5",
        "outputId": "d7db59f6-2a85-4d18-b339-04358afb1962"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before dropout: tensor([[1., 1., 1., 1., 1.]])\n",
            "After dropout: tensor([[0., 0., 2., 2., 2.]])\n",
            "Dropout prevents overfitting by randomly turning off neurons\n",
            "\n",
            "Before BatchNorm - mean: tensor([4., 5., 6.])\n",
            "After BatchNorm - mean: tensor([0., 0., 0.], grad_fn=<MeanBackward1>)\n",
            "BatchNorm helps with training stability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q5Z5vzrKZ6bi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8qBAwxvICqIS0xE8fL63r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}